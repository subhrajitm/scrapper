version: '3.8'

services:
  # Redis for Celery message broker and result backend
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Main Flask application
  legalscrape:
    build: .
    ports:
      - "5000:5000"
    environment:
      - GOOGLE_CSE_API_KEY=${GOOGLE_CSE_API_KEY}
      - GOOGLE_CSE_CX=${GOOGLE_CSE_CX}
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///data/legalscrape.db
      - USE_PLAYWRIGHT=${USE_PLAYWRIGHT:-false}
    volumes:
      - ./data:/app/data  # Persist SQLite database
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery worker for background scraping jobs
  celery-worker:
    build: .
    command: celery -A celery_config worker --loglevel=info --concurrency=2
    environment:
      - GOOGLE_CSE_API_KEY=${GOOGLE_CSE_API_KEY}
      - GOOGLE_CSE_CX=${GOOGLE_CSE_CX}
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///data/legalscrape.db
      - USE_PLAYWRIGHT=${USE_PLAYWRIGHT:-false}
    volumes:
      - ./data:/app/data
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Celery beat for scheduled tasks (cache cleanup)
  celery-beat:
    build: .
    command: celery -A celery_config beat --loglevel=info
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///data/legalscrape.db
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

volumes:
  redis_data:
